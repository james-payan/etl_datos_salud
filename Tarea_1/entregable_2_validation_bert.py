# -*- coding: utf-8 -*-
"""Entregable_2_validation_bert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rd2DHhFzs0U0JsFAjRlK3PlfC09cK7Ev

# Validación Modelo jamesopeth/bert-base-uncased-finetuned-ner-lung-cancer

* Verificamos que están disponibles todas las dependencias
"""

!pip install datasets transformers
!pip install seqeval
!pip install -U datasets evaluate
!pip install -U huggingface_hub

"""* Hacemos login en la plataforma de Hugging Face"""

from huggingface_hub import login

# token cuenta personal, maestria_laptop_james_lectura
maestria_laptop_james_lectura = '___TOKEN___PRUEBA____'
login(maestria_laptop_james_lectura)

"""* Cargamos la configuración, el tokenizer y el modelo preentrenado previamente"""

from transformers import AutoConfig
from transformers import AutoTokenizer, AutoModelForTokenClassification
import torch

hugging_face_NER_model="jamesopeth/bert-base-uncased-finetuned-ner-lung-cancer"
config = AutoConfig.from_pretrained(hugging_face_NER_model)
id2label = config.id2label
label2id = config.label2id
num_labels = config.num_labels

model = AutoModelForTokenClassification.from_pretrained(hugging_face_NER_model,
        num_labels = num_labels,
        id2label = id2label,
        label2id = {v: k for k, v in id2label.items()}
)

tokenizer = AutoTokenizer.from_pretrained(hugging_face_NER_model, use_fast = True)


# Usar GPU si está disponible
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)



all_results = []
batch_size = 8

"""* Algunos ejemplos para validar el modelo"""

texts = [
    "Paciente con carcinoma escamoso de pulmón estadio IIIB.",
    "Se inicia tratamiento con quimioterapia basada en Carboplatino y Paclitaxel.",
    "Fumadora crónica con diagnóstico reciente de adenocarcinoma pulmonar.",
    "TC muestra masa pulmonar de aspecto neoplásico en lóbulo superior derecho.",
    "Histología reporta carcinoma de células no pequeñas.",
    "Se planifica cirugía torácica para resección del tumor primario.",
    "Estadio clínico T2N1M0 confirmado por TAC y PET.",
    "Paciente exfumador en vigilancia por nódulo pulmonar sospechoso.",
    "Indicada radioterapia como tratamiento adyuvante tras lobectomía.",
    "Biopsia muestra tumor neuroendocrino de célula grande en pulmón izquierdo."
]

# Tokenización
encodings = tokenizer(
        texts,
        truncation=True,
        padding=True,
        return_offsets_mapping=True,
        return_attention_mask=True,
        return_token_type_ids=False,
        max_length=512,
        is_split_into_words=False
        )

"""* Realizamos las predicciones usando el modelo preentrenado cargado"""

import torch
import torch.nn.functional as F

input_ids = torch.tensor(encodings["input_ids"]).to(device)

attention_mask = torch.tensor(encodings["attention_mask"]).to(device)


with torch.no_grad():
 outputs = model(input_ids=input_ids, attention_mask=attention_mask)

logits = outputs.logits
predictions = torch.argmax(logits, dim=-1)
probs = F.softmax(logits, dim=-1)

### Para cada oracion en la lista de oraciones.
for i, text in enumerate(texts):
  word_ids = encodings.word_ids(batch_index=i)
  tokens = tokenizer.convert_ids_to_tokens(encodings["input_ids"][i])
  print("\n \n=================================================================================================\n")
  print (word_ids)
  print (tokens)


  previous_word_id = None
  aligned_words, aligned_labels, aligned_scores = [], [], []

  for token, label_id, word_id in zip(tokens, predictions[i].tolist(), word_ids):
  #print (token, " ", label_id, " ", word_id)

    if word_id is None:
      continue


    if word_id != previous_word_id:
        aligned_words.append(token.replace("##", ""))  # WordPiece tokens
        aligned_labels.append(id2label[label_id])
        aligned_scores.append(probs[i][word_id][label_id].item())
    else:
        aligned_words[-1] += token.replace("##", "")
    previous_word_id = word_id



  filtered_results = [
            (word, label, score)
            for word, label, score in zip(aligned_words, aligned_labels, aligned_scores)
            if label != "O"
  ]

  ###Resultados
  print("\n ")
  print("Palabras: ", aligned_words)
  print("Labels: ", aligned_labels)
  print("Score: ", aligned_scores)
  print("\n ")

for i, text in enumerate(texts):
    word_ids = encodings.word_ids(batch_index=i)
    tokens = tokenizer.convert_ids_to_tokens(encodings["input_ids"][i])
    print("\n\n=================================================================================================\n")
    print(word_ids)
    print(tokens)

    previous_word_id = None
    aligned_words, aligned_labels, aligned_scores = [], [], []

    for token, label_id, word_id in zip(tokens, predictions[i].tolist(), word_ids):
        if word_id is None:
            continue

        # Unir subtokens con WordPiece (##) limpiamente
        if word_id != previous_word_id:
            aligned_words.append(token.replace("##", ""))
            aligned_labels.append(id2label[label_id])
            aligned_scores.append(probs[i][word_id][label_id].item())
        else:
            aligned_words[-1] += token.replace("##", "")
        previous_word_id = word_id

    # Filtrar etiquetas diferentes a 'O'
    filtered_results = [
        (word, label, score)
        for word, label, score in zip(aligned_words, aligned_labels, aligned_scores)
        if label != "O"
    ]

    # Mostrar alineación cruda
    print("\nPalabras: ", aligned_words)
    print("Labels: ", aligned_labels)
    print("Score: ", aligned_scores)

    ### Combinar etiquetas B- y I- en una sola entidad
    print("\n**** Se unen las etiquetas B, I en una sola entidad ****\n")
    combined_results = []
    temp_entity, temp_label, temp_score = "", "", 0

    for word, label, score in filtered_results:
        if label.startswith("B_"):
            if temp_entity:
                combined_results.append((temp_entity, temp_label, temp_score))
            temp_entity, temp_label, temp_score = word, label, score
        elif label.startswith("I_") and label[2:] == temp_label[2:]:
            temp_entity += " " + word
            temp_score += score
        else:
            if temp_entity:
                combined_results.append((temp_entity, temp_label, temp_score))
            temp_entity, temp_label, temp_score = word, label, score

    if temp_entity:
        combined_results.append((temp_entity, temp_label, temp_score))

    for entity, label, score in combined_results:
        result = {
            "Palabra": entity,
            "Entidad": label[2:],  # remove B_ or I_
            "Score": round(score, 4)
        }
        print(result)
        all_results.append(result)

    print("\n")